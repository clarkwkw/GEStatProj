{
    "headline": "Exam boards hit by scandals and criticism", 
    "text": "Exam boards in England, Wales and Northern Ireland may feel under siege. In recent weeks, the scandal of examiners allegedly giving too much help to teachers about future papers during training sessions  a subject covered by Education Guardian in 2009  has been hitting the headlines. And a string of errors in last summer&apos;s exam papers led to an investigation by the watchdog Ofqual, which has concluded that while generally the boards met regulatory requirements, there were quality &quot;issues&quot; at all awarding bodies. Now, as we await publication of the secondary league tables, a survey of English teachers carried out by the National Association for the Teaching of English (Nate) has identified the quality of marking as the largest worry among those teaching the subject at A-level. A report in the latest edition of Nate&apos;s journal says: &quot;The quality and consistency of examination marking  has led to a crisis in confidence about the ability of [exam boards] to employ markers and deploy procedures that can guarantee accurate results.&quot; Ofqual surveys have found that, across all subjects, nearly three quarters of A-level teachers have confidence in the quality of marking, against 20% who do not. However, the Nate survey, completed by 144 teachers, found plenty of expressions of frustration. One respondent wrote: &quot;Our results were totally out of line with predictions and we were very concerned about the quality of the marking.&quot; Another wrote of &quot;shocking inaccuracy and inconsistency, and no apology for the distress caused&quot;. Other comments included: &quot;the gap between the most generous and most severe markers is a scandal&quot; and &quot;instances of erratic marking and moderation have increased, with some frankly bizarre results, and re-marks resulting in sometimes huge shifts [in the marks]&quot;. Kevin Rogers, an English teacher and assistant curriculum manager at Bilborough College, Nottingham, says his c150 English language AS-level students had an &quot;unhappy&quot; experience last summer. When results came back from the AQA board, teachers were surprised at the unusually small number of As and Bs. Eyebrows were further raised when staff went through students&apos; completed scripts. &quot;Often we could not really see how the comments related to the script itself,&quot; says Rogers, &quot; so we would struggle to see how the student had ended up with the mark they had.&quot; In the end, all scripts were sent back for a re-mark, and 43 of the 150 students had their marks improved. But it took until November. This can have big repercussions for students, some of whom will drop a subject after the AS exams if their first result suggests they are not doing as well as expected. Rogers adds that, with teachers and institutions also judged on pupils&apos; exam grades, poor marking can provoke months of misplaced soul-searching by staff. An experienced English A-level examiner, speaking on condition of anonymity, says the boards have impressive systems for checking that erratic marking is picked up. However, there are strains. &quot;There is enormous pressure on the boards, seemingly from the government, for results to get out faster and faster,&quot; she says. There are pressures on individuals, too. Typically, a marker might be allocated 200 A-level English scripts. The examiner says it would be &quot;amazing&quot; to get through three in an hour, suggesting a commitment in excess of 65 hours. With many examiners also teaching, this means a lot of work in evenings and weekends. Occasionally, she says, an examiner faced with too much work might just leave scripts unmarked until the board tracked them down. Very rarely, a marker would be found to have marked too fast in a rush to earn money: pay rates for A-level English are typically around 6 per script. The examiner added that in the scenarios described above, however, the boards would typically allocate very senior markers to these problem scripts, and the issue would be well handled. Schools and colleges, she added, could sometimes feel aggrieved when students did not meet their predicted grades even though, on occasion, teachers had been over-generous with their predictions. Meanwhile, an official working for the OCR exam board has made seemingly far more damning claims against procedures for investigating examiners&apos; mistakes. In evidence to the Commons education select committee, David Leitch, a supervisor working for OCR&apos;s parent body, Cambridge Assessment, says that senior OCR managers tried to stop further checks being carried out on the accuracy of examiners&apos; marks after he and colleagues found 300 students&apos; scripts containing basic mistakes in markers&apos; adding-up. At least 80 examiners were found to be at fault. The mistakes were first uncovered last August. Leitch says that in October, when discussing the matter, managers had not wanted to tell schools, colleges and students about them. Leitch reported the matter to Ofqual, and following this, extra checks were carried out by OCR. An OCR spokesman says that managers had sought not to make changes to grades until after a thorough investigation. Eventually, in all instances where clerical errors were found, and where this was to the candidate&apos;s detriment, marks were changed. In only a few cases did this affect the overall grade: eight students&apos; AS grades, two A-level grades and four GCSE grades improved as a result. Over the years, exam boards have argued that the number of grades changed following a re-mark is very small as a percentage of papers taken. Ofqual figures show that this year, across all subjects, 12,245 A-level papers had grades changed on re-marking, which equates to only 0.48%. However, the number of grades changed has grown by nearly 50% since 2007. It rose 16% last year alone. Brian Lightman, general secretary of the Association of School and College Leaders, says English is a particularly contentious subject, since subjectivity will always be greater than in maths and science. But he adds: &quot;In general, the exams system is under strain because of the number of changes that are made to it [by ministers].&quot; Critics will also point to the implications of sheer scale. Some 16 million GCSE and A-level papers were sat last summer. Measures put forward by Michael Gove, the education secretary, including the ending of multiple modular papers at GCSE, may take some pressure off. But the exams regime will remain under close scrutiny, since the results are now so important to students, teachers and schools.", 
    "section": "education", 
    "gid": "education/2012/jan/02/a-level-criticism-exam-boards", 
    "wordcount": "1068"
}