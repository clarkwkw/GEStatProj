{
    "headline": "Can we trust a model that predicts traffic chaos during the Olympics?", 
    "text": "All sorts of records will tumble at the London Olympics, but Londoners will be hoping that their city doesn&apos;t break one on the opening weekend of the games and host the world&apos;s most congested road network. According to the results of a computer model developed by the traffic analysis company Inrix, severe congestion levels are expected on the streets of the capital. Transport for London (TfL) responded by saying the Inrix report was incorrect, claiming it was full of factual inaccuracies and was based on out-of-date information. Whom should we believe? The issue here is the reliability and usefulness of the mathematical model. Models can help us understand complex processes and predict what will happen in various future scenarios, like the effects of particular Olympic events on public transport and the road network. But, like a cake, they are only as good as the ingredients and skill that are used to make them. There are a few underlying ideas that are key to good model building. Often the real-world systems people are interested in, like London&apos;s traffic flow, are complex. They are incredibly difficult to represent exactly. Using a model is a way to simplify the problem. Models are an abstraction of reality so they are necessarily imperfect. The statistician George Box famously said that all models are wrong, but some are useful. So, building a model requires the builder to make assumptions. The modeller must decide which things to include and which to leave out. What are the features of the problem that are most important to have and what won&apos;t make much of a difference to the output if they&apos;re left on the shelf? To illustrate this with an extreme example, the speed limits on the road network would be more important than what colour the cars are. Central to constructing a model are the data. How the data were collected, by whom, when and where are all considerations. For example, what is the size of the data set, what data are missing and how precise are they? You can&apos;t expect the output to be any more accurate than the data you&apos;re using to produce it. Things can also change over time and out-of-date data, as Transport for London claims, may give incorrect results. The modelling approach or philosophy also needs to be decided. How is uncertainty handled? How complex should the model be to meet its purpose? What are the constraints on the model-building process? Considerations like how much time there is available to run the model, or how powerful the computer is that it will run on, may be important in answering such questions. If the computer model only finishes running after the closing ceremony then it is obviously useless, no matter how accurate its results. These model-building decisions may be enforced from outside, or the modeller&apos;s own judgement calls. Often they are not set in stone and there is not necessarily a right answer. Most useful models are constantly evolving, being refined, compared and improved as choices are made between alternative options. &quot;Model validation&quot; is an important step in the model-building process whereby the outputs are checked against actual data. Models serve a useful purpose in informing a decision, even if they&apos;re not necessarily used to make it. But if the worst comes to the worst, and the Inrix predictions come true, Londoners will have plenty of time to ponder the intricacies of model-building while they&apos;re sitting in traffic jams this summer.", 
    "section": "science", 
    "gid": "science/blog/2012/jan/27/how-good-model", 
    "wordcount": "579"
}